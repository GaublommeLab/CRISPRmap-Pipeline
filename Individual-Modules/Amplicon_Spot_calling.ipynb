{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "447a35d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import math\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy.ndimage as ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import glob\n",
    "from skimage.filters import threshold_local\n",
    "from skimage.filters import threshold_li\n",
    "from skimage.color import rgb2gray\n",
    "from math import sqrt\n",
    "from skimage.morphology import disk, ball\n",
    "from skimage.feature import blob_dog, blob_log, blob_doh\n",
    "from skimage.filters.rank import enhance_contrast\n",
    "from skimage.exposure import adjust_gamma\n",
    "import pickle as pkl\n",
    "import sys\n",
    "from datetime import date\n",
    "import os, psutil\n",
    "import re\n",
    "process = psutil.Process(os.getpid())\n",
    "# Grab utilities from the imaging directories dir\n",
    "utilsDir = re.sub(r'Registration', 'Imaging Utilities', str(sys.path[0]))\n",
    "# Homebrew utilities for importing ims files & basic image manipulation\n",
    "sys.path.append(utilsDir)\n",
    "from functools import reduce\n",
    "from scipy.spatial.distance import cdist, pdist\n",
    "from skimage.exposure import rescale_intensity\n",
    "from skimage.segmentation import find_boundaries\n",
    "\n",
    "# Use this function for local thresholding of images\n",
    "def lthresh(imgstk):\n",
    "    th = threshold_local(imgstk, 65, offset=0)\n",
    "    imgstk = imgstk>= th\n",
    "    return imgstk\n",
    "# Use this function to threshold images\n",
    "def thresh(imgstk):\n",
    "    th = threshold_li(imgstk)\n",
    "    imgstk = imgstk>= th\n",
    "    return imgstk\n",
    "def spotcall(img, min_sig, max_sig, nsig, th):\n",
    "    blobs_log = blob_log(img, min_sigma=min_sig, max_sigma=max_sig, num_sigma=nsig, threshold=th)\n",
    "    # Compute radii in the 3rd column.\n",
    "    blobs_log[:, 2] = blobs_log[:, 2] * sqrt(2)\n",
    "    color = 'lime'\n",
    "    title = 'Laplacian of Gaussian'\n",
    "    return blobs_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d202b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          R1  R2  R3  R4  R5  R6  R7  R8  R9  R10  ...  R15  \\\n",
      "Gene                                                               ...        \n",
      "AAVS1-controls-AAVS1.100   0   1   0   0   0   0   0   0   0    0  ...    0   \n",
      "AAVS1-controls-AAVS1.103   0   0   0   0   0   0   0   0   0    0  ...    0   \n",
      "AAVS1-controls-AAVS1.105   0   0   0   1   0   0   0   1   0    0  ...    0   \n",
      "AAVS1-controls-AAVS1.106   0   0   0   0   0   0   1   0   0    0  ...    0   \n",
      "AAVS1-controls-AAVS1.108   1   0   0   0   0   0   0   0   0    0  ...    0   \n",
      "...                       ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...   \n",
      "Core-RAD51D.51             1   0   0   0   0   1   0   0   1    0  ...    0   \n",
      "Core-RECQL.109             1   0   0   0   0   0   0   0   1    0  ...    1   \n",
      "Core-RECQL.71              1   0   0   0   0   0   0   0   1    0  ...    0   \n",
      "Core-WRN.125               1   0   1   0   0   0   0   0   1    0  ...    0   \n",
      "Core-XRCC3.198             0   0   0   0   0   0   0   0   0    1  ...    0   \n",
      "\n",
      "                          R16  R17  R18  R19  R20  R21  R22  R23  R24  \n",
      "Gene                                                                   \n",
      "AAVS1-controls-AAVS1.100    1    0    0    0    0    0    0    0    0  \n",
      "AAVS1-controls-AAVS1.103    1    0    0    1    0    0    0    0    0  \n",
      "AAVS1-controls-AAVS1.105    1    0    0    0    0    0    0    0    0  \n",
      "AAVS1-controls-AAVS1.106    1    0    0    0    1    0    0    0    0  \n",
      "AAVS1-controls-AAVS1.108    1    1    0    0    0    0    0    0    0  \n",
      "...                       ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "Core-RAD51D.51              0    0    0    0    0    0    0    1    0  \n",
      "Core-RECQL.109              0    0    0    0    0    1    0    0    0  \n",
      "Core-RECQL.71               0    0    0    0    0    0    0    0    1  \n",
      "Core-WRN.125                0    0    1    0    0    0    0    0    0  \n",
      "Core-XRCC3.198              0    1    0    0    1    0    1    0    0  \n",
      "\n",
      "[364 rows x 24 columns]\n",
      "(24,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "codebook = '/mnt/disks/external/jg4159/BEpilot/DDR364_codebook.csv'\n",
    "cb = pd.read_csv(codebook, sep=',', header=0, index_col='Gene')\n",
    "print(cb)\n",
    "cb_list = np.asarray(cb.values.tolist(),dtype=bool)\n",
    "genes = cb.index.tolist()\n",
    "print(np.asarray(cb_list[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b39e0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1_1\n",
      "14793\n",
      "Exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/external/jg4159/.conda/envs/cellpose/lib/python3.7/site-packages/skimage/feature/blob.py:125: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  r1 = blob1[-1] / blob2[-1]\n",
      "/mnt/disks/external/jg4159/.conda/envs/cellpose/lib/python3.7/site-packages/skimage/feature/blob.py:126: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  pos1 = blob1[:ndim] / (max_sigma * root_ndim)\n",
      "/mnt/disks/external/jg4159/.conda/envs/cellpose/lib/python3.7/site-packages/skimage/feature/blob.py:127: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  pos2 = blob2[:ndim] / (max_sigma * root_ndim)\n",
      "/mnt/disks/external/jg4159/.conda/envs/cellpose/lib/python3.7/site-packages/skimage/feature/blob.py:129: RuntimeWarning: invalid value encountered in subtract\n",
      "  d = np.sqrt(np.sum((pos2 - pos1)**2))\n",
      "/mnt/disks/external/jg4159/.conda/envs/cellpose/lib/python3.7/site-packages/skimage/feature/blob.py:126: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pos1 = blob1[:ndim] / (max_sigma * root_ndim)\n",
      "/mnt/disks/external/jg4159/.conda/envs/cellpose/lib/python3.7/site-packages/skimage/feature/blob.py:127: RuntimeWarning: invalid value encountered in true_divide\n",
      "  pos2 = blob2[:ndim] / (max_sigma * root_ndim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of unique spots: 655716\n",
      "Total guide spots:  207891\n",
      "Guide spots/Total spots: 207891 / 655716 = 0.31704426916530937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/external/jg4159/.conda/envs/cellpose/lib/python3.7/site-packages/ipykernel_launcher.py:205: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9175\n",
      "0.6202257824646792\n",
      "P1_2\n",
      "22485\n",
      "Exists!\n",
      "Total # of unique spots: 1237543\n",
      "Total guide spots:  249157\n",
      "Guide spots/Total spots: 249157 / 1237543 = 0.20133199412060834\n",
      "12233\n",
      "0.5440515899488548\n"
     ]
    }
   ],
   "source": [
    "runlist= ['P1_1','P1_2','P1_3','P1_4','P1_5','P1_6'] #,'P1_7','P1_8','P1_9','P2_1','P2_2','P2_3','P2_4','P2_5', 'P2_6','P2_7','P2_8','P2_9'\n",
    "opdir = '/mnt/disks/external/jg4159/20231006_DDR364/' # Path to output \n",
    "for runName in runlist:\n",
    "    print(runName)\n",
    "    ip = opdir + \"RegisteredImages_CM_\" + runName + \".pkl\" # the registered image stack containing all CM rounds\n",
    "    filehandler = open(ip, 'rb')\n",
    "    img_stack = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "    mk = opdir + \"Unfiltered_segmentation_DDR364_\"+runName+\"*.pickle\" # the segmentation files\n",
    "    lof = glob.glob(mk)\n",
    "    filehandler = open(lof[0], 'rb')\n",
    "    masks_mem,masks_nuc,ref_mem = pkl.load(filehandler)\n",
    "    print(len(ref_mem))\n",
    "    filehandler.close()\n",
    "\n",
    "    # rescale the registered images to unit16\n",
    "    for img in img_stack:\n",
    "        for i in range(img.shape[0]):\n",
    "            img[i] *= 65535\n",
    "            img[i] = img[i].astype(np.uint16)\n",
    "            m = np.median(img[i][img[i] > 0])\n",
    "            \n",
    "    # rescale the images by setting lower and upper thresholds\n",
    "    num_chn = 3\n",
    "    num_cyc = 8\n",
    "\n",
    "    gamstack=[]\n",
    "    for i in range(num_cyc):\n",
    "            for j in range(num_chn):\n",
    "                if (j<2): #640 or 561 channel\n",
    "                    gamstack.append(rescale_intensity(img_stack[i][j], (108,115), (0, 255)))\n",
    "                else: #488 channel\n",
    "                    gamstack.append(rescale_intensity(img_stack[i][j],(108,112), (0, 255)))\n",
    "\n",
    "    # check if memMaskgd exists\n",
    "    try:\n",
    "        filehandler = open(opdir+'memMaskgd0_reverse_' + runName + '.pkl', 'rb')\n",
    "        memMaskgd0 = pkl.load(filehandler)\n",
    "        filehandler.close()\n",
    "    except:\n",
    "        memMaskgd_exists = False\n",
    "    else:\n",
    "        print(\"Exists!\")\n",
    "        memMaskgd_exists = True\n",
    "    # make config if it does not exist already (e.g. passed in by papermill) for manual running\n",
    "    if not(memMaskgd_exists):\n",
    "        start_time = time.time()\n",
    "        memMaskgd0 = {}\n",
    "        i=0\n",
    "        for key in ref_mem.keys():\n",
    "            if i%1000==0:\n",
    "                print(i)\n",
    "            i=i+1\n",
    "            spgd={}\n",
    "            x0 = ref_mem[key][\"Membrane Pixels 2D\"][0]\n",
    "            y0 = ref_mem[key][\"Membrane Pixels 2D\"][1]\n",
    "            cellset = set([tuple([x,y]) for x,y in zip(x0,y0)]) #save all pixels for this cell\\n\",\n",
    "            spgd['cellset']=cellset\n",
    "            memMaskgd0[key] = spgd\n",
    "        print(f'--- generate memeMaskgd0: {(time.time()-start_time)} seconds')\n",
    "        filehandler = open(opdir+'memMaskgd0_reverse_' + runName + '.pkl', 'wb')\n",
    "        pkl.dump(memMaskgd0, filehandler)\n",
    "        filehandler.close()\n",
    "        \n",
    "    # spot calling \n",
    "    spot_df = pd.DataFrame(0,columns = range(len(gamstack)), \n",
    "                       index = memMaskgd0.keys())\n",
    "    all_spots = np.zeros(shape=(0,3))\n",
    "    total_spots_cycle = []\n",
    "    retained_spots_cycle = []\n",
    "    spotlist = []\n",
    "    bkg_spot_th = 3 # remove scattered spots to reduce the spot matrix density\n",
    "    cyc=0\n",
    "    for img in gamstack:\n",
    "        spots = spotcall(img[:,:],min_sig=2,max_sig=10,nsig=1,th=0.5)# Decrease threshold if spots are not identified and min sigma if spots are smaller\\n\",\n",
    "        spotset = set([tuple(x) for x in spots[:,:2].astype(int)])\n",
    "        retained_spots= []\n",
    "        num_retained = 0\n",
    "        for key, values in memMaskgd0.items():\n",
    "            cellset=memMaskgd0[key][\"cellset\"]  # all 2d pixel positions for this mem id    \n",
    "            spcell = np.array([[x[0],x[1],1] for x in spotset & cellset]) # find pixels (i.e. spots) that are in both spotset & cellset\n",
    "            spot_df.loc[key, cyc] = len(spcell)\n",
    "            if len(spcell) >= bkg_spot_th:\n",
    "                num_retained = num_retained + len(spcell)\n",
    "                spcell = spcell.tolist()\n",
    "                retained_spots.extend(spcell)\n",
    "        spotlist.append(np.array(retained_spots))\n",
    "        total_spots_cycle.append(len(spots))\n",
    "        retained_spots_cycle.append(len(retained_spots))\n",
    "        all_spots = np.concatenate((all_spots, retained_spots), axis=0)\n",
    "        cyc=cyc+1\n",
    "    all_spots = np.unique(all_spots, axis=0)\n",
    "    print(\"Total # of unique spots:\", all_spots.shape[0])\n",
    "    total_spots = all_spots.shape[0]\n",
    "    # save the spot coordinates\n",
    "    filehandler = open(opdir+'Spotcalling_spotlist_108115&108112_' + str(total_spots) + \"_\" + runName + '.pkl', 'wb')\n",
    "    pkl.dump(spotlist, filehandler)\n",
    "    filehandler.close()\n",
    "    filehandler = open(opdir+'Spotcalling_allspots_108115&108112_' + str(total_spots) + \"_\"  + runName + '.pkl', 'wb')\n",
    "    pkl.dump(all_spots, filehandler)\n",
    "    filehandler.close()\n",
    "    spot_df.to_csv(opdir+runName+'_'+str(total_spots)+'_108115&108112_spotbycycle.csv')\n",
    "    \n",
    "    # Amplicon decoding\n",
    "    xmax = gamstack[0].shape[0]\n",
    "    ymax = gamstack[0].shape[1]\n",
    "    del gamstack\n",
    "    spotset=[]\n",
    "    for j in spotlist:\n",
    "        spotset.append(set([tuple(x) for x in j[:,:2]]))\n",
    "    num_chn=3\n",
    "    num_cyc=8\n",
    "    num_pxl_list=[2.01]#test different radius if necessary\n",
    "    guide_spots_list=[]\n",
    "    for num_pxl in num_pxl_list:    \n",
    "        ## Guide detection, generating the bitcode by searching the spot pixel in all cycles within a given radius\n",
    "        cycles = np.zeros((all_spots.shape[0],num_chn*num_cyc),dtype=bool)\n",
    "        for i in range(all_spots.shape[0]): #all_spots.shape[0]\n",
    "            k = 0\n",
    "            # given a spot i\n",
    "            spot_i = np.reshape(all_spots[i,:2],[1,2])[0]\n",
    "            grid = [] \n",
    "            for dx in range(math.ceil(num_pxl)):  # give the radius is 2, we can pre-set a coordinate set of 2x2 grid and find spots that fall within the grid, calculate distance if any\n",
    "                for dy in range(math.ceil(num_pxl)):\n",
    "                    coord1 = tuple([np.max([0,spot_i[0]-dx]).astype(int), np.max([0,spot_i[1]-dy]).astype(int)])\n",
    "                    #print(coord1)\n",
    "                    grid.append(coord1)\n",
    "                    coord2 = tuple([np.min([xmax, spot_i[0]+dx]).astype(int), np.min([ymax, spot_i[1]+dy]).astype(int)])\n",
    "                    #print(coord2)\n",
    "                    grid.append(coord2)\n",
    "                    coord3 = tuple([np.max([0, spot_i[0]-dx]).astype(int), np.min([ymax, spot_i[1]+dy]).astype(int)])\n",
    "                    grid.append(coord3)\n",
    "                    coord4 = tuple([np.min([xmax, spot_i[0]+dx]).astype(int), np.max([0, spot_i[1]-dy]).astype(int)])\n",
    "                    grid.append(coord4)\n",
    "            grid = set(grid)      \n",
    "            for j in spotset:  \n",
    "                spcell = np.array([[x[0],x[1]] for x in grid & j])\n",
    "                if len(spcell>0): # if there is a spot within this grid\n",
    "                    a = cdist(np.reshape(all_spots[i,:2],[1,2]), spcell, metric='euclidean') # calculate the cdist of the current spot to all the other spots found in the grid\n",
    "                    if np.min(a) < num_pxl: # if the cdist is less than the num_pxl pixels \n",
    "                        cycles[i,k]=1\n",
    "                k = k+1\n",
    "\n",
    "    # de-duplicaton\n",
    "        spotdict = {}\n",
    "        guide_spots=0\n",
    "        for j in range(len(cb_list)):\n",
    "            k = 0\n",
    "            abc = []\n",
    "            dedup = []\n",
    "            for i in range(0, cycles.shape[0]):\n",
    "                if np.array_equal(cycles[i,:], np.asarray(cb_list[j])):\n",
    "                    k=k+1\n",
    "                    abc.append(all_spots[i])\n",
    "            spotcycle = np.asarray(abc)\n",
    "            for sp in range(spotcycle.shape[0]):\n",
    "                a = cdist(np.reshape(spotcycle[sp,:2],[1,2]), spotcycle[:,:2], metric='euclidean')#distance\n",
    "                if len(np.where(a<num_pxl)[1]) > 1:\n",
    "                    dedup.append(spotcycle[np.where(a<num_pxl)[1][0],:])\n",
    "                else:\n",
    "                    dedup.append(spotcycle[sp,:])\n",
    "            spotdict[genes[j]] = np.unique(np.asarray(dedup),axis=0)\n",
    "            guide_spots = guide_spots + len(dedup)\n",
    "        print(\"Total guide spots: \", guide_spots)\n",
    "        print(\"Guide spots/Total spots:\", guide_spots, '/', total_spots, '=', guide_spots/total_spots)\n",
    "        guide_spots_list.append(guide_spots)\n",
    "        # Save the guide spot ds' coordinates\n",
    "        filehandler = open(opdir+'Spots-with-dist-108115&108112_numpxl='+str(num_pxl)+\"_\"+str(guide_spots)+\"_\" + runName + '.pkl', 'wb')\n",
    "        pkl.dump(spotdict, filehandler)\n",
    "        filehandler.close()\n",
    "\n",
    "        # Create a dictionary where every key is a foci coordinate, and the value is the guide identity\n",
    "        spotMatch = {}\n",
    "        names = list(spotdict.keys())\n",
    "        for i, guide in enumerate(spotdict):\n",
    "            for spot in spotdict[guide]:\n",
    "                if spotMatch.get((spot[0], spot[1])):\n",
    "                    spotMatch[(spot[0], spot[1])].append(names[i])\n",
    "                else:\n",
    "                    spotMatch[(spot[0], spot[1])] = [names[i]]\n",
    "\n",
    "        # create an empty dataframe with cell_id and guide names\n",
    "        mem_df = pd.DataFrame(0,columns = spotdict.keys(), \n",
    "                           index = memMaskgd0.keys())        \n",
    "\n",
    "        # For each nuclei, see which spots in the membrane are indexed in the key \n",
    "        for i, cellID in enumerate(memMaskgd0):\n",
    "            for name in names:\n",
    "                memMaskgd0[cellID][name] = 0\n",
    "\n",
    "            # For each Mmebrane Coordinate set, look for a spot\n",
    "            memCoord = memMaskgd0[cellID]['cellset']\n",
    "            for coord in memCoord:\n",
    "                amplicons = spotMatch.get(coord)\n",
    "                if amplicons:\n",
    "                    for amplicon in amplicons:\n",
    "                        memMaskgd0[cellID][amplicon] += 1\n",
    "                        mem_df.loc[cellID,amplicon] += 1\n",
    "\n",
    "        mem_max = mem_df.max(axis='columns') # guide with the max num of spots\n",
    "        mem_sec = mem_df.apply(lambda x: x.nlargest(2).iloc[1], axis=1)\n",
    "        max_idx = mem_df.idxmax(axis=1)\n",
    "        guide_num = 0\n",
    "        for i, cellID in enumerate(ref_mem):\n",
    "            guide_spot_ratio = mem_max[cellID]/(mem_max[cellID] + mem_sec[cellID]) # guide purity\n",
    "            if mem_max[cellID] >= 3 and guide_spot_ratio >= 0.67:\n",
    "                ref_mem[cellID]['Guide ID'] = max_idx[cellID]\n",
    "                guide_num = guide_num + 1\n",
    "            else:\n",
    "                ref_mem[cellID]['Guide ID'] = \"None\"\n",
    "        print(guide_num)\n",
    "        print(guide_num/len(ref_mem))\n",
    "        mem_df.to_csv(opdir+runName+'_108115&108112_'+str(guide_spots)+\"spots_\"+str(guide_num)+'cells_cell2guide.csv')\n",
    "        # check nucleus presence in all cycles and save as an entry in ref_mem\n",
    "        th = 105\n",
    "        for key in ref_mem.keys(): \n",
    "            round_sum = 0\n",
    "            # Get Indices of Nuclei volume & append to dictionary\n",
    "            nuc_pxls = ref_mem[key]['Nuclei Pixels']\n",
    "            # Get the most common membrane mask value for that location in a given round\n",
    "            for i in range(len(img_stack)):\n",
    "                x=img_stack[i][3].ravel()\n",
    "                x = x > th # binarized\n",
    "                cur_id = stats.mode(x[nuc_pxls])[0] # 1 or 0\n",
    "                round_sum = round_sum + cur_id\n",
    "            # Save within a sub dictionary\n",
    "            sub_dict1 = dict()\n",
    "            sub_dict1['round_sum'] = round_sum\n",
    "            # save the sub dictionary\n",
    "            ref_mem[key].update(sub_dict1)\n",
    "        # save the dict with guide and roundsum info\n",
    "        filehandler = open(opdir+'ref_mem_roundsum_108115&108112_' + runName + '.pkl', 'wb')\n",
    "        pkl.dump((masks_mem,masks_nuc,ref_mem), filehandler)\n",
    "        filehandler.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
